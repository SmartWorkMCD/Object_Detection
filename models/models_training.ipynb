{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Object Detection - Models Training**\n",
    "\n",
    "---\n",
    "\n",
    "**Mateus Aleixo - 124256**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from glob import glob\n",
    "import os\n",
    "import random\n",
    "from rfdetr import RFDETRBase\n",
    "import shutil\n",
    "import torch\n",
    "from ultralytics import YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image_label_pairs(\n",
    "    image_root, annotation_root, image_ext=\"jpg\", label_ext=\"txt\"\n",
    "):\n",
    "    pairs = []\n",
    "    image_files = glob(os.path.join(image_root, \"**\", f\"*.{image_ext}\"), recursive=True)\n",
    "\n",
    "    for img in image_files:\n",
    "        rel_path = os.path.relpath(img, image_root)\n",
    "        label = os.path.join(\n",
    "            annotation_root, os.path.splitext(rel_path)[0] + f\".{label_ext}\"\n",
    "        )\n",
    "\n",
    "        if os.path.exists(label):\n",
    "            pairs.append((img, label))\n",
    "        else:\n",
    "            print(f\"Warning: Label file not found for image {img}\")\n",
    "\n",
    "    return pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3864 image-label pairs.\n"
     ]
    }
   ],
   "source": [
    "image_root = \"../data/augmented_data/frames\"\n",
    "annotation_root = \"../data/annotations\"\n",
    "pairs = get_image_label_pairs(image_root, annotation_root)\n",
    "print(f\"Found {len(pairs)} image-label pairs.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 0 empty label files.\n"
     ]
    }
   ],
   "source": [
    "empty_files = []\n",
    "\n",
    "for root, _, files in os.walk(annotation_root):\n",
    "    for file in files:\n",
    "        file_path = os.path.join(root, file)\n",
    "\n",
    "        if os.stat(file_path).st_size == 0:\n",
    "            empty_files.append(file_path)\n",
    "\n",
    "print(f\"Found {len(empty_files)} empty label files.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'1': 7728, '2': 7728, '3': 7728, '0': 7726, '4': 7694})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_counts = Counter()\n",
    "\n",
    "for root, _, files in os.walk(annotation_root):\n",
    "    for file in files:\n",
    "        with open(os.path.join(root, file), \"r\") as f:\n",
    "            lines = f.readlines()\n",
    "\n",
    "            for line in lines:\n",
    "                class_id = line.split()[0]\n",
    "                label_counts[class_id] += 1\n",
    "\n",
    "label_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset split completed: 2704 train, 772 val, 388 test\n"
     ]
    }
   ],
   "source": [
    "# Paths\n",
    "image_dir = \"../data/augmented_data/frames\"\n",
    "label_dir = \"../data/annotations\"\n",
    "output_dir = \"../data/split_data\"\n",
    "\n",
    "# Create output folders\n",
    "for split in [\"train\", \"val\", \"test\"]:\n",
    "    os.makedirs(os.path.join(output_dir, \"images\", split), exist_ok=True)\n",
    "    os.makedirs(os.path.join(output_dir, \"labels\", split), exist_ok=True)\n",
    "\n",
    "# Get all images\n",
    "all_images = []\n",
    "for root, _, files in os.walk(image_dir):\n",
    "    for file in files:\n",
    "        if file.endswith(\".jpg\") or file.endswith(\".png\"):\n",
    "            all_images.append(os.path.join(root, file))\n",
    "\n",
    "# Shuffle and split\n",
    "random.shuffle(all_images)\n",
    "train_ratio = 0.7\n",
    "val_ratio = 0.2\n",
    "train_count = int(len(all_images) * train_ratio)\n",
    "val_count = int(len(all_images) * val_ratio)\n",
    "\n",
    "train_images = all_images[:train_count]\n",
    "val_images = all_images[train_count : train_count + val_count]\n",
    "test_images = all_images[train_count + val_count :]\n",
    "\n",
    "# Move files\n",
    "def move_files(image_list, split):\n",
    "    for img_path in image_list:\n",
    "        # Get label path\n",
    "        rel_path = os.path.relpath(img_path, image_dir)\n",
    "        label_path = os.path.join(label_dir, os.path.splitext(rel_path)[0] + \".txt\")\n",
    "\n",
    "        # Define new paths\n",
    "        new_img_path = os.path.join(\n",
    "            output_dir, \"images\", split, os.path.basename(img_path)\n",
    "        )\n",
    "        new_label_path = os.path.join(\n",
    "            output_dir, \"labels\", split, os.path.basename(label_path)\n",
    "        )\n",
    "\n",
    "        # Copy files\n",
    "        shutil.copy(img_path, new_img_path)\n",
    "        if os.path.exists(label_path):\n",
    "            shutil.copy(label_path, new_label_path)\n",
    "\n",
    "\n",
    "# Move train, val & test files\n",
    "move_files(train_images, \"train\")\n",
    "move_files(val_images, \"val\")\n",
    "move_files(test_images, \"test\")\n",
    "\n",
    "print(\n",
    "    f\"Dataset split completed: {len(train_images)} train, {len(val_images)} val, {len(test_images)} test\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.3.102 available  Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.40  Python-3.12.9 torch-2.6.0+cpu CPU (AMD Ryzen 7 6800H with Radeon Graphics)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0mtask=detect, mode=train, model=yolo11n.pt, data=../data/dataset.yaml, epochs=22, time=None, patience=3, batch=8, imgsz=416, save=True, save_period=-1, cache=False, device=cpu, workers=8, project=None, name=train, exist_ok=False, pretrained=True, optimizer=AdamW, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.001, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=10, translate=0.2, scale=0.5, shear=2.0, perspective=0.001, flipud=0.5, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.2, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=c:\\Users\\mateu\\Downloads\\UA\\Cadeiras\\Seminrio\\Object_Detection\\ultralytics\\runs\\detect\\train\n",
      "Overriding model.yaml nc=80 with nc=5\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      6640  ultralytics.nn.modules.block.C3k2            [32, 64, 1, False, 0.25]      \n",
      "  3                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      "  4                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n",
      "  5                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      "  6                  -1  1     87040  ultralytics.nn.modules.block.C3k2            [128, 128, 1, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    346112  ultralytics.nn.modules.block.C3k2            [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1    249728  ultralytics.nn.modules.block.C2PSA           [256, 256, 1]                 \n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 13                  -1  1    111296  ultralytics.nn.modules.block.C3k2            [384, 128, 1, False]          \n",
      " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 16                  -1  1     32096  ultralytics.nn.modules.block.C3k2            [256, 64, 1, False]           \n",
      " 17                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 19                  -1  1     86720  ultralytics.nn.modules.block.C3k2            [192, 128, 1, False]          \n",
      " 20                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 22                  -1  1    378880  ultralytics.nn.modules.block.C3k2            [384, 256, 1, True]           \n",
      " 23        [16, 19, 22]  1    431647  ultralytics.nn.modules.head.Detect           [5, [64, 128, 256]]           \n",
      "YOLO11n summary: 319 layers, 2,590,815 parameters, 2,590,799 gradients, 6.4 GFLOPs\n",
      "\n",
      "Transferred 448/499 items from pretrained weights\n",
      "Freezing layer 'model.23.dfl.conv.weight'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\mateu\\Downloads\\UA\\Cadeiras\\Seminário\\Object_Detection\\data\\split_data\\labels\\train... 1918 images, 0 backgrounds, 0 corrupt: 100%|██████████| 1918/1918 [00:02<00:00, 714.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: C:\\Users\\mateu\\Downloads\\UA\\Cadeiras\\Seminrio\\Object_Detection\\data\\split_data\\labels\\train.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, num_output_channels=3, method='weighted_average'), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "UserWarning: Argument(s) 'quality_lower' are not valid for transform ImageCompression\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\mateu\\Downloads\\UA\\Cadeiras\\Seminário\\Object_Detection\\data\\split_data\\labels\\val... 710 images, 0 backgrounds, 0 corrupt: 100%|██████████| 710/710 [00:00<00:00, 788.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: C:\\Users\\mateu\\Downloads\\UA\\Cadeiras\\Seminrio\\Object_Detection\\data\\split_data\\labels\\val.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to c:\\Users\\mateu\\Downloads\\UA\\Cadeiras\\Seminrio\\Object_Detection\\ultralytics\\runs\\detect\\train\\labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001, momentum=0.937) with parameter groups 81 weight(decay=0.0), 88 weight(decay=0.0005), 87 bias(decay=0.0)\n",
      "Image sizes 416 train, 416 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1mc:\\Users\\mateu\\Downloads\\UA\\Cadeiras\\Seminrio\\Object_Detection\\ultralytics\\runs\\detect\\train\u001b[0m\n",
      "Starting training for 22 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       1/22         0G      2.007      2.041     0.9297        135        416: 100%|██████████| 240/240 [03:06<00:00,  1.29it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 45/45 [00:19<00:00,  2.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        710       7084      0.564       0.66      0.713       0.38\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       2/22         0G      1.771      1.188     0.8923        129        416: 100%|██████████| 240/240 [02:46<00:00,  1.44it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 45/45 [00:20<00:00,  2.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        710       7084      0.896      0.917      0.955      0.504\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       3/22         0G      1.701     0.9849     0.8788        222        416: 100%|██████████| 240/240 [02:51<00:00,  1.40it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 45/45 [00:20<00:00,  2.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        710       7084      0.941      0.947      0.977      0.628\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       4/22         0G      1.638      0.901     0.8747        110        416: 100%|██████████| 240/240 [02:50<00:00,  1.41it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 45/45 [00:21<00:00,  2.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        710       7084      0.947      0.962      0.982      0.591\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       5/22         0G       1.57      0.845     0.8654        154        416: 100%|██████████| 240/240 [02:47<00:00,  1.43it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 45/45 [00:19<00:00,  2.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        710       7084      0.951      0.953      0.982      0.655\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       6/22         0G      1.536      0.806     0.8608        105        416: 100%|██████████| 240/240 [02:45<00:00,  1.45it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 45/45 [00:19<00:00,  2.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        710       7084      0.951      0.968      0.982      0.615\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       7/22         0G      1.506     0.7702     0.8563        150        416: 100%|██████████| 240/240 [02:41<00:00,  1.48it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 45/45 [00:19<00:00,  2.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        710       7084      0.973      0.973      0.986      0.681\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       8/22         0G      1.451     0.7388     0.8541         67        416: 100%|██████████| 240/240 [02:43<00:00,  1.47it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 45/45 [00:19<00:00,  2.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        710       7084      0.976      0.972      0.987      0.686\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       9/22         0G      1.436     0.7196     0.8511         87        416: 100%|██████████| 240/240 [02:42<00:00,  1.47it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 45/45 [00:20<00:00,  2.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        710       7084      0.978       0.98      0.987      0.621\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      10/22         0G      1.422     0.7125     0.8497        133        416: 100%|██████████| 240/240 [02:41<00:00,  1.48it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 45/45 [00:18<00:00,  2.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        710       7084      0.978      0.981      0.988      0.702\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      11/22         0G       1.41     0.6876     0.8454         54        416: 100%|██████████| 240/240 [02:46<00:00,  1.44it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 45/45 [00:19<00:00,  2.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        710       7084      0.981      0.985      0.988      0.678\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      12/22         0G      1.363     0.6733     0.8445        126        416: 100%|██████████| 240/240 [03:32<00:00,  1.13it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 45/45 [00:36<00:00,  1.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        710       7084      0.981      0.988      0.989      0.722\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing dataloader mosaic\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, num_output_channels=3, method='weighted_average'), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UserWarning: Argument(s) 'quality_lower' are not valid for transform ImageCompression\n",
      "      13/22         0G      1.166     0.5831     0.8301         60        416: 100%|██████████| 240/240 [04:41<00:00,  1.17s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 45/45 [00:35<00:00,  1.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        710       7084      0.981      0.983      0.989      0.731\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      14/22         0G      1.138     0.5601     0.8252         60        416: 100%|██████████| 240/240 [04:33<00:00,  1.14s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 45/45 [00:35<00:00,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        710       7084      0.983      0.985      0.989       0.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      15/22         0G      1.108     0.5472     0.8256         60        416: 100%|██████████| 240/240 [04:33<00:00,  1.14s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 45/45 [00:35<00:00,  1.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        710       7084      0.986      0.988       0.99       0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      16/22         0G      1.091     0.5361     0.8208         60        416: 100%|██████████| 240/240 [04:34<00:00,  1.14s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 45/45 [00:35<00:00,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        710       7084      0.986      0.986       0.99      0.745\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      17/22         0G      1.084     0.5295     0.8216         60        416: 100%|██████████| 240/240 [02:41<00:00,  1.49it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 45/45 [00:17<00:00,  2.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        710       7084      0.984      0.989      0.991      0.756\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      18/22         0G      1.026     0.5073     0.8181         60        416: 100%|██████████| 240/240 [02:22<00:00,  1.68it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 45/45 [00:21<00:00,  2.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        710       7084      0.987      0.989       0.99      0.736\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      19/22         0G       1.04     0.5053     0.8177         60        416: 100%|██████████| 240/240 [02:29<00:00,  1.60it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 45/45 [00:18<00:00,  2.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        710       7084      0.986       0.99      0.991       0.77\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      20/22         0G     0.9966     0.4895     0.8136         60        416: 100%|██████████| 240/240 [02:25<00:00,  1.65it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 45/45 [00:19<00:00,  2.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        710       7084      0.987       0.99      0.991       0.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      21/22         0G     0.9964     0.4866     0.8134         60        416: 100%|██████████| 240/240 [02:27<00:00,  1.62it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 45/45 [00:18<00:00,  2.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        710       7084      0.987       0.99       0.99      0.771\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      22/22         0G     0.9891     0.4836     0.8129         60        416: 100%|██████████| 240/240 [02:25<00:00,  1.65it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 45/45 [00:19<00:00,  2.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        710       7084      0.988      0.991       0.99      0.786\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "22 epochs completed in 1.272 hours.\n",
      "Optimizer stripped from c:\\Users\\mateu\\Downloads\\UA\\Cadeiras\\Seminrio\\Object_Detection\\ultralytics\\runs\\detect\\train\\weights\\last.pt, 5.5MB\n",
      "Optimizer stripped from c:\\Users\\mateu\\Downloads\\UA\\Cadeiras\\Seminrio\\Object_Detection\\ultralytics\\runs\\detect\\train\\weights\\best.pt, 5.5MB\n",
      "\n",
      "Validating c:\\Users\\mateu\\Downloads\\UA\\Cadeiras\\Seminrio\\Object_Detection\\ultralytics\\runs\\detect\\train\\weights\\best.pt...\n",
      "Ultralytics 8.3.40  Python-3.12.9 torch-2.6.0+cpu CPU (AMD Ryzen 7 6800H with Radeon Graphics)\n",
      "YOLO11n summary (fused): 238 layers, 2,583,127 parameters, 0 gradients, 6.3 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 45/45 [00:17<00:00,  2.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        710       7084      0.988      0.991       0.99      0.786\n",
      "                  blue        710       1420      0.998      0.998      0.994      0.817\n",
      "                 green        710       1420      0.983      0.984      0.989      0.746\n",
      "                orange        710       1420      0.988      0.989      0.989      0.794\n",
      "                   red        710       1420      0.991      0.991      0.992      0.793\n",
      "                yellow        702       1404      0.979      0.993      0.988      0.781\n",
      "Speed: 0.4ms preprocess, 17.9ms inference, 0.0ms loss, 0.3ms postprocess per image\n",
      "Results saved to \u001b[1mc:\\Users\\mateu\\Downloads\\UA\\Cadeiras\\Seminrio\\Object_Detection\\ultralytics\\runs\\detect\\train\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "yolo = YOLO(verbose=False)\n",
    "\n",
    "results = yolo.train(\n",
    "    data=\"../data/dataset.yaml\",\n",
    "    epochs=22,\n",
    "    batch=8,\n",
    "    imgsz=416,\n",
    "    device=\"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
    "    optimizer=\"AdamW\",\n",
    "    lr0=0.001,\n",
    "    lrf=0.01,\n",
    "    weight_decay=0.0005,\n",
    "    patience=3,\n",
    "    degrees=10,\n",
    "    translate=0.2,\n",
    "    scale=0.5,\n",
    "    shear=2.0,\n",
    "    perspective=0.001,\n",
    "    flipud=0.5,\n",
    "    fliplr=0.5,\n",
    "    mosaic=1.0,\n",
    "    mixup=0.2,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
