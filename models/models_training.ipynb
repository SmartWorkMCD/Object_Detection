{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Object Detection - Models Training**\n",
    "\n",
    "---\n",
    "\n",
    "**Mateus Aleixo - 124256**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from glob import glob\n",
    "import os\n",
    "import random\n",
    "import shutil\n",
    "import torch\n",
    "from ultralytics import YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image_label_pairs(\n",
    "    image_root, annotation_root, image_ext=\"jpg\", label_ext=\"txt\"\n",
    "):\n",
    "    pairs = []\n",
    "    image_files = glob(os.path.join(image_root, \"**\", f\"*.{image_ext}\"), recursive=True)\n",
    "\n",
    "    for img in image_files:\n",
    "        rel_path = os.path.relpath(img, image_root)\n",
    "        label = os.path.join(\n",
    "            annotation_root, os.path.splitext(rel_path)[0] + f\".{label_ext}\"\n",
    "        )\n",
    "\n",
    "        if os.path.exists(label):\n",
    "            pairs.append((img, label))\n",
    "        else:\n",
    "            print(f\"Warning: Label file not found for image {img}\")\n",
    "\n",
    "    return pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3864 image-label pairs.\n"
     ]
    }
   ],
   "source": [
    "image_root = \"../data/augmented_data/frames\"\n",
    "annotation_root = \"../data/annotations\"\n",
    "pairs = get_image_label_pairs(image_root, annotation_root)\n",
    "print(f\"Found {len(pairs)} image-label pairs.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 0 empty label files.\n"
     ]
    }
   ],
   "source": [
    "empty_files = []\n",
    "\n",
    "for root, _, files in os.walk(annotation_root):\n",
    "    for file in files:\n",
    "        file_path = os.path.join(root, file)\n",
    "\n",
    "        if os.stat(file_path).st_size == 0:\n",
    "            empty_files.append(file_path)\n",
    "\n",
    "print(f\"Found {len(empty_files)} empty label files.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'1': 7728, '2': 7728, '3': 7728, '0': 7726, '4': 7694})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_counts = Counter()\n",
    "\n",
    "for root, _, files in os.walk(annotation_root):\n",
    "    for file in files:\n",
    "        with open(os.path.join(root, file), \"r\") as f:\n",
    "            lines = f.readlines()\n",
    "\n",
    "            for line in lines:\n",
    "                class_id = line.split()[0]\n",
    "                label_counts[class_id] += 1\n",
    "\n",
    "label_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset split completed: 3091 train, 773 val\n"
     ]
    }
   ],
   "source": [
    "# Paths\n",
    "image_dir = \"../data/augmented_data/frames\"\n",
    "label_dir = \"../data/annotations\"\n",
    "output_dir = \"../data/split_data\"\n",
    "\n",
    "# Create output folders\n",
    "for split in [\"train\", \"val\"]:\n",
    "    os.makedirs(os.path.join(output_dir, \"images\", split), exist_ok=True)\n",
    "    os.makedirs(os.path.join(output_dir, \"labels\", split), exist_ok=True)\n",
    "\n",
    "# Get all images\n",
    "all_images = []\n",
    "for root, _, files in os.walk(image_dir):\n",
    "    for file in files:\n",
    "        if file.endswith(\".jpg\") or file.endswith(\".png\"):\n",
    "            all_images.append(os.path.join(root, file))\n",
    "\n",
    "# Shuffle and split\n",
    "random.shuffle(all_images)\n",
    "train_ratio = 0.8\n",
    "train_count = int(len(all_images) * train_ratio)\n",
    "\n",
    "train_images = all_images[:train_count]\n",
    "val_images = all_images[train_count:]\n",
    "\n",
    "\n",
    "# Move files\n",
    "def move_files(image_list, split):\n",
    "    for img_path in image_list:\n",
    "        # Get label path\n",
    "        rel_path = os.path.relpath(img_path, image_dir)\n",
    "        label_path = os.path.join(label_dir, os.path.splitext(rel_path)[0] + \".txt\")\n",
    "\n",
    "        # Define new paths\n",
    "        new_img_path = os.path.join(\n",
    "            output_dir, \"images\", split, os.path.basename(img_path)\n",
    "        )\n",
    "        new_label_path = os.path.join(\n",
    "            output_dir, \"labels\", split, os.path.basename(label_path)\n",
    "        )\n",
    "\n",
    "        # Copy files\n",
    "        shutil.copy(img_path, new_img_path)\n",
    "        if os.path.exists(label_path):\n",
    "            shutil.copy(label_path, new_label_path)\n",
    "\n",
    "\n",
    "# Move train & val files\n",
    "move_files(train_images, \"train\")\n",
    "move_files(val_images, \"val\")\n",
    "\n",
    "print(f\"Dataset split completed: {len(train_images)} train, {len(val_images)} val\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.3.101 available  Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.40  Python-3.12.9 torch-2.6.0+cpu CPU (AMD Ryzen 7 6800H with Radeon Graphics)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0mtask=detect, mode=train, model=yolo11n.pt, data=../data/dataset.yaml, epochs=22, time=None, patience=5, batch=8, imgsz=416, save=True, save_period=-1, cache=False, device=cpu, workers=8, project=None, name=train, exist_ok=False, pretrained=True, optimizer=AdamW, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.001, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=10, translate=0.2, scale=0.5, shear=2.0, perspective=0.001, flipud=0.5, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.2, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=c:\\Users\\mateu\\Downloads\\UA\\Cadeiras\\Seminrio\\Object_Detection\\ultralytics\\runs\\detect\\train\n",
      "Overriding model.yaml nc=80 with nc=5\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      6640  ultralytics.nn.modules.block.C3k2            [32, 64, 1, False, 0.25]      \n",
      "  3                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      "  4                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n",
      "  5                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      "  6                  -1  1     87040  ultralytics.nn.modules.block.C3k2            [128, 128, 1, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    346112  ultralytics.nn.modules.block.C3k2            [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1    249728  ultralytics.nn.modules.block.C2PSA           [256, 256, 1]                 \n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 13                  -1  1    111296  ultralytics.nn.modules.block.C3k2            [384, 128, 1, False]          \n",
      " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 16                  -1  1     32096  ultralytics.nn.modules.block.C3k2            [256, 64, 1, False]           \n",
      " 17                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 19                  -1  1     86720  ultralytics.nn.modules.block.C3k2            [192, 128, 1, False]          \n",
      " 20                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 22                  -1  1    378880  ultralytics.nn.modules.block.C3k2            [384, 256, 1, True]           \n",
      " 23        [16, 19, 22]  1    431647  ultralytics.nn.modules.head.Detect           [5, [64, 128, 256]]           \n",
      "YOLO11n summary: 319 layers, 2,590,815 parameters, 2,590,799 gradients, 6.4 GFLOPs\n",
      "\n",
      "Transferred 448/499 items from pretrained weights\n",
      "Freezing layer 'model.23.dfl.conv.weight'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\mateu\\Downloads\\UA\\Cadeiras\\Seminário\\Object_Detection\\data\\split_data\\labels\\train... 2203 images, 0 backgrounds, 0 corrupt: 100%|██████████| 2203/2203 [00:03<00:00, 675.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: C:\\Users\\mateu\\Downloads\\UA\\Cadeiras\\Seminrio\\Object_Detection\\data\\split_data\\labels\\train.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, num_output_channels=3, method='weighted_average'), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mateu\\Downloads\\UA\\Cadeiras\\Seminário\\Object_Detection\\.venv\\Lib\\site-packages\\ultralytics\\data\\augment.py:1850: UserWarning: Argument(s) 'quality_lower' are not valid for transform ImageCompression\n",
      "  A.ImageCompression(quality_lower=75, p=0.0),\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\mateu\\Downloads\\UA\\Cadeiras\\Seminário\\Object_Detection\\data\\split_data\\labels\\val... 1179 images, 0 backgrounds, 0 corrupt: 100%|██████████| 1179/1179 [00:01<00:00, 820.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: C:\\Users\\mateu\\Downloads\\UA\\Cadeiras\\Seminrio\\Object_Detection\\data\\split_data\\labels\\val.cache\n",
      "Plotting labels to c:\\Users\\mateu\\Downloads\\UA\\Cadeiras\\Seminrio\\Object_Detection\\ultralytics\\runs\\detect\\train\\labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001, momentum=0.937) with parameter groups 81 weight(decay=0.0), 88 weight(decay=0.0005), 87 bias(decay=0.0)\n",
      "Image sizes 416 train, 416 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1mc:\\Users\\mateu\\Downloads\\UA\\Cadeiras\\Seminrio\\Object_Detection\\ultralytics\\runs\\detect\\train\u001b[0m\n",
      "Starting training for 22 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       1/22         0G      1.993      1.925     0.9288         25        416: 100%|██████████| 276/276 [03:30<00:00,  1.31it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 74/74 [00:36<00:00,  2.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1179      11782       0.73      0.776      0.824      0.398\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       2/22         0G      1.787      1.125     0.8896         61        416: 100%|██████████| 276/276 [03:10<00:00,  1.45it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 74/74 [00:34<00:00,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1179      11782      0.891      0.892       0.95      0.555\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       3/22         0G       1.65     0.9418      0.877         40        416: 100%|██████████| 276/276 [03:05<00:00,  1.49it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 74/74 [00:32<00:00,  2.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1179      11782      0.924      0.937      0.975      0.625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       4/22         0G      1.579     0.8644     0.8685         51        416: 100%|██████████| 276/276 [03:11<00:00,  1.44it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 74/74 [00:32<00:00,  2.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1179      11782      0.957      0.961      0.984      0.589\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       5/22         0G      1.566     0.8287     0.8637         70        416: 100%|██████████| 276/276 [03:05<00:00,  1.49it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 74/74 [00:32<00:00,  2.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1179      11782      0.967      0.967      0.987      0.658\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       6/22         0G      1.498     0.7792       0.86         39        416: 100%|██████████| 276/276 [03:05<00:00,  1.49it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 74/74 [00:31<00:00,  2.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1179      11782      0.967      0.964      0.987      0.639\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       7/22         0G      1.479      0.756     0.8563         60        416: 100%|██████████| 276/276 [02:57<00:00,  1.56it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 74/74 [00:30<00:00,  2.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1179      11782      0.973      0.975       0.99      0.697\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       8/22         0G      1.457     0.7324     0.8532         92        416: 100%|██████████| 276/276 [03:01<00:00,  1.52it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 74/74 [00:31<00:00,  2.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1179      11782       0.98      0.977       0.99      0.708\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       9/22         0G      1.401     0.7014     0.8466         46        416: 100%|██████████| 276/276 [03:05<00:00,  1.48it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 74/74 [00:33<00:00,  2.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1179      11782      0.982      0.981      0.991      0.698\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      10/22         0G      1.407     0.6954     0.8462         48        416: 100%|██████████| 276/276 [03:12<00:00,  1.44it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 74/74 [00:33<00:00,  2.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1179      11782      0.982      0.982      0.991      0.705\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      11/22         0G      1.366     0.6714     0.8447         51        416: 100%|██████████| 276/276 [03:07<00:00,  1.47it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 74/74 [00:32<00:00,  2.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1179      11782      0.984      0.984      0.992      0.724\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      12/22         0G      1.349     0.6594     0.8427         52        416: 100%|██████████| 276/276 [03:05<00:00,  1.49it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 74/74 [00:32<00:00,  2.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1179      11782      0.988      0.985      0.992      0.734\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing dataloader mosaic\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, num_output_channels=3, method='weighted_average'), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mateu\\Downloads\\UA\\Cadeiras\\Seminário\\Object_Detection\\.venv\\Lib\\site-packages\\ultralytics\\data\\augment.py:1850: UserWarning: Argument(s) 'quality_lower' are not valid for transform ImageCompression\n",
      "  A.ImageCompression(quality_lower=75, p=0.0),\n",
      "      13/22         0G      1.164     0.5757      0.829         30        416: 100%|██████████| 276/276 [02:52<00:00,  1.60it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 74/74 [00:32<00:00,  2.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1179      11782      0.987      0.986      0.992      0.697\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      14/22         0G      1.115       0.55     0.8246         30        416: 100%|██████████| 276/276 [02:52<00:00,  1.60it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 74/74 [00:32<00:00,  2.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1179      11782      0.987      0.987      0.992      0.733\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      15/22         0G      1.096     0.5389     0.8228         30        416: 100%|██████████| 276/276 [02:53<00:00,  1.59it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 74/74 [00:32<00:00,  2.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1179      11782       0.99      0.989      0.992      0.759\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      16/22         0G       1.06     0.5196     0.8194         30        416: 100%|██████████| 276/276 [02:53<00:00,  1.59it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 74/74 [00:32<00:00,  2.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1179      11782      0.991      0.989      0.992      0.774\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      17/22         0G      1.042     0.5135     0.8173         30        416: 100%|██████████| 276/276 [02:53<00:00,  1.59it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 74/74 [00:32<00:00,  2.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1179      11782      0.991      0.991      0.993      0.764\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      18/22         0G      1.036      0.507     0.8166         30        416: 100%|██████████| 276/276 [02:54<00:00,  1.59it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 74/74 [00:32<00:00,  2.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1179      11782       0.99      0.991      0.992      0.699\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      19/22         0G      1.007     0.4928     0.8153         30        416: 100%|██████████| 276/276 [02:52<00:00,  1.60it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 74/74 [00:32<00:00,  2.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1179      11782      0.991      0.992      0.993       0.78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      20/22         0G     0.9734     0.4785     0.8125         30        416: 100%|██████████| 276/276 [02:58<00:00,  1.55it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 74/74 [00:32<00:00,  2.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1179      11782      0.991      0.992      0.993      0.754\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      21/22         0G      0.963     0.4738     0.8099         30        416: 100%|██████████| 276/276 [02:54<00:00,  1.58it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 74/74 [00:32<00:00,  2.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1179      11782      0.992      0.992      0.993      0.787\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      22/22         0G     0.9554     0.4668     0.8111         28        416: 100%|██████████| 276/276 [02:53<00:00,  1.59it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 74/74 [00:32<00:00,  2.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1179      11782      0.993      0.992      0.993      0.769\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "22 epochs completed in 1.312 hours.\n",
      "Optimizer stripped from c:\\Users\\mateu\\Downloads\\UA\\Cadeiras\\Seminrio\\Object_Detection\\ultralytics\\runs\\detect\\train\\weights\\last.pt, 5.5MB\n",
      "Optimizer stripped from c:\\Users\\mateu\\Downloads\\UA\\Cadeiras\\Seminrio\\Object_Detection\\ultralytics\\runs\\detect\\train\\weights\\best.pt, 5.5MB\n",
      "\n",
      "Validating c:\\Users\\mateu\\Downloads\\UA\\Cadeiras\\Seminrio\\Object_Detection\\ultralytics\\runs\\detect\\train\\weights\\best.pt...\n",
      "Ultralytics 8.3.40  Python-3.12.9 torch-2.6.0+cpu CPU (AMD Ryzen 7 6800H with Radeon Graphics)\n",
      "YOLO11n summary (fused): 238 layers, 2,583,127 parameters, 0 gradients, 6.3 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 74/74 [00:28<00:00,  2.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1179      11782      0.992      0.992      0.993      0.788\n",
      "                  blue       1179       2358      0.995      0.996      0.992      0.807\n",
      "                 green       1179       2358       0.99      0.982      0.993      0.752\n",
      "                orange       1179       2358      0.994      0.994      0.993      0.797\n",
      "                   red       1179       2358       0.99      0.996      0.993      0.801\n",
      "                yellow       1175       2350       0.99      0.993      0.992       0.78\n",
      "Speed: 0.4ms preprocess, 17.5ms inference, 0.0ms loss, 0.3ms postprocess per image\n",
      "Results saved to \u001b[1mc:\\Users\\mateu\\Downloads\\UA\\Cadeiras\\Seminrio\\Object_Detection\\ultralytics\\runs\\detect\\train\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "model = YOLO(verbose=False)\n",
    "\n",
    "results = model.train(\n",
    "    data=\"../data/dataset.yaml\",\n",
    "    epochs=22,\n",
    "    batch=8,\n",
    "    imgsz=416,\n",
    "    device=\"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
    "    optimizer=\"AdamW\",\n",
    "    lr0=0.001,\n",
    "    lrf=0.01,\n",
    "    weight_decay=0.0005,\n",
    "    patience=5,\n",
    "    degrees=10,\n",
    "    translate=0.2,\n",
    "    scale=0.5,\n",
    "    shear=2.0,\n",
    "    perspective=0.001,\n",
    "    flipud=0.5,\n",
    "    fliplr=0.5,\n",
    "    mosaic=1.0,\n",
    "    mixup=0.2,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
