{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a6ee912c",
   "metadata": {},
   "source": [
    "# **Object Detection - Models Testing - YOLO**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97c38dd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "25a4fd81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.40  Python-3.12.9 torch-2.5.1+cu121 CUDA:0 (NVIDIA GeForce RTX 3060 Laptop GPU, 6144MiB)\n",
      "YOLO11n summary (fused): 238 layers, 2,583,127 parameters, 0 gradients, 6.3 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\mateu\\Downloads\\UA\\Cadeiras\\Seminário\\Object_Detection\\data\\split_data\\labels\\test.cache... 376 images, 0 backgrounds, 0 corrupt: 100%|██████████| 376/376 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 24/24 [00:04<00:00,  5.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        376       3758      0.992      0.995      0.994      0.793\n",
      "                  blue        376        752      0.999      0.999      0.995      0.817\n",
      "                 green        376        752      0.984      0.988      0.993      0.755\n",
      "                orange        376        752      0.993      0.996      0.994      0.804\n",
      "                   red        376        752      0.993      0.997      0.995      0.799\n",
      "                yellow        375        750      0.989      0.992      0.993      0.788\n",
      "Speed: 0.2ms preprocess, 3.0ms inference, 0.0ms loss, 1.4ms postprocess per image\n",
      "Results saved to \u001b[1mc:\\Users\\mateu\\Downloads\\UA\\Cadeiras\\Seminrio\\Object_Detection\\ultralytics\\runs\\detect\\val\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "yolo = YOLO(\"../../ultralytics/runs/detect/train/weights/best.pt\")\n",
    "results = yolo.val(data=\"../../data/dataset.yaml\", split=\"test\", save=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "82ec57b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 c:\\Users\\mateu\\Downloads\\UA\\Cadeiras\\Seminrio\\Object_Detection\\models\\notebooks\\..\\..\\data\\test_image.jpg: 320x416 2 blues, 2 greens, 2 oranges, 2 reds, 2 yellows, 42.5ms\n",
      "Speed: 1.0ms preprocess, 42.5ms inference, 2.0ms postprocess per image at shape (1, 3, 320, 416)\n",
      "Results:\n",
      "ultralytics.engine.results.Results object with attributes:\n",
      "\n",
      "boxes: ultralytics.engine.results.Boxes object\n",
      "keypoints: None\n",
      "masks: None\n",
      "names: {0: 'blue', 1: 'green', 2: 'orange', 3: 'red', 4: 'yellow'}\n",
      "obb: None\n",
      "orig_img: array([[[26,  7,  2],\n",
      "        [26,  7,  2],\n",
      "        [26,  7,  2],\n",
      "        ...,\n",
      "        [ 2,  3,  1],\n",
      "        [ 2,  3,  1],\n",
      "        [ 2,  3,  1]],\n",
      "\n",
      "       [[26,  7,  2],\n",
      "        [26,  7,  2],\n",
      "        [26,  7,  2],\n",
      "        ...,\n",
      "        [ 2,  3,  1],\n",
      "        [ 2,  3,  1],\n",
      "        [ 2,  3,  1]],\n",
      "\n",
      "       [[26,  7,  2],\n",
      "        [26,  7,  2],\n",
      "        [26,  7,  2],\n",
      "        ...,\n",
      "        [ 2,  3,  1],\n",
      "        [ 2,  3,  1],\n",
      "        [ 2,  3,  1]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[59, 26, 10],\n",
      "        [59, 26, 10],\n",
      "        [59, 26, 10],\n",
      "        ...,\n",
      "        [ 1,  2,  0],\n",
      "        [ 1,  2,  0],\n",
      "        [ 1,  2,  0]],\n",
      "\n",
      "       [[59, 26, 10],\n",
      "        [59, 26, 10],\n",
      "        [59, 26, 10],\n",
      "        ...,\n",
      "        [ 1,  2,  0],\n",
      "        [ 1,  2,  0],\n",
      "        [ 1,  2,  0]],\n",
      "\n",
      "       [[59, 26, 10],\n",
      "        [59, 26, 10],\n",
      "        [59, 26, 10],\n",
      "        ...,\n",
      "        [ 1,  2,  0],\n",
      "        [ 1,  2,  0],\n",
      "        [ 1,  2,  0]]], shape=(480, 640, 3), dtype=uint8)\n",
      "orig_shape: (480, 640)\n",
      "path: 'c:\\\\Users\\\\mateu\\\\Downloads\\\\UA\\\\Cadeiras\\\\Seminário\\\\Object_Detection\\\\models\\\\notebooks\\\\..\\\\..\\\\data\\\\test_image.jpg'\n",
      "probs: None\n",
      "save_dir: 'c:\\\\Users\\\\mateu\\\\Downloads\\\\UA\\\\Cadeiras\\\\Seminário\\\\Object_Detection\\\\ultralytics\\\\runs\\\\detect\\\\predict'\n",
      "speed: {'preprocess': 1.0006427764892578, 'inference': 42.51360893249512, 'postprocess': 2.001523971557617}\n"
     ]
    }
   ],
   "source": [
    "test_image_path = \"../../data/test_image.jpg\"\n",
    "results = yolo(test_image_path)[0]\n",
    "print(\"Results:\")\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7d346ded",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[     303.99,      304.75,       322.9,      322.01],\n",
       "       [     293.35,      331.22,      316.87,      349.11],\n",
       "       [     264.63,      251.52,      288.01,      269.62],\n",
       "       [     335.65,      309.67,      352.97,      330.16],\n",
       "       [     348.66,       244.6,      367.64,       262.9],\n",
       "       [     299.77,      271.82,      323.13,       289.3],\n",
       "       [     350.87,      275.06,      369.03,      296.95],\n",
       "       [     334.48,      325.73,       351.9,      343.68],\n",
       "       [      322.3,      297.88,      343.75,      315.47],\n",
       "       [     272.42,      269.72,      290.88,         288]], dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.boxes.xyxy.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "acd735d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([    0.87745,     0.87639,     0.87597,      0.8709,     0.86141,      0.8518,     0.83962,     0.81557,     0.81235,     0.80033], dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.boxes.conf.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8b265392",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['blue',\n",
       " 'blue',\n",
       " 'orange',\n",
       " 'orange',\n",
       " 'yellow',\n",
       " 'green',\n",
       " 'yellow',\n",
       " 'green',\n",
       " 'red',\n",
       " 'red']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes = [results.names[int(c)] for c in results.boxes.cls.cpu().numpy()]\n",
    "classes"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
